{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tzBMuvI41k2"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# Load your dataset (update the file path)\n",
        "file_path = r'/content/SILKYSKY_DATA_CW2 (S).csv'\n",
        "df = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
        "\n",
        "# 1. Encode categorical columns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "df['Gender'] = label_encoder.fit_transform(df['Gender'])\n",
        "df['Satisfied'] = label_encoder.fit_transform(df['Satisfied'])\n",
        "df['Age Band'] = label_encoder.fit_transform(df['Age Band'])\n",
        "df['Type of Travel'] = label_encoder.fit_transform(df['Type of Travel'])\n",
        "df['Class'] = label_encoder.fit_transform(df['Class'])\n",
        "df['Destination'] = label_encoder.fit_transform(df['Destination'])\n",
        "df['Continent'] = label_encoder.fit_transform(df['Continent'])\n",
        "\n",
        "# 2. Handle missing values for 'Arrival Delay in Minutes'\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "df['Arrival Delay in Minutes'] = imputer.fit_transform(df[['Arrival Delay in Minutes']])\n",
        "\n",
        "# 3. Split dataset into features (X) and target (y)\n",
        "X = df.drop(columns=['Satisfied', 'Ref', 'id'])  # Drop the target and irrelevant columns\n",
        "y = df['Satisfied']\n",
        "\n",
        "# 4. Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 6. Define hyperparameters to tune for XGBoost\n",
        "param_grid = {\n",
        "    'learning_rate': [0.01, 0.1, 0.3],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'colsample_bytree': [0.8, 1.0],\n",
        "    'gamma': [0, 0.1, 0.3]\n",
        "}\n",
        "\n",
        "# 7. Create the GridSearchCV object for XGBoost\n",
        "xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
        "grid_search_xgb = GridSearchCV(xgb, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# 8. Fit the grid search to the training data\n",
        "grid_search_xgb.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 9. Best model from grid search\n",
        "best_xgb = grid_search_xgb.best_estimator_\n",
        "\n",
        "# 10. Predict and evaluate the accuracy of the best model\n",
        "y_pred_best = best_xgb.predict(X_test_scaled)\n",
        "best_accuracy = accuracy_score(y_test, y_pred_best)\n",
        "\n",
        "print(\"Best Parameters:\", grid_search_xgb.best_params_)\n",
        "print(\"Best Accuracy:\", best_accuracy)\n"
      ]
    }
  ]
}